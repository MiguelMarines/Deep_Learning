{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**DEEP LEARNING - MIGUEL MARINES**\n",
        "##**<u>Transformers</u>**\n",
        "###**<u>Language Translator</u>**\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "bg_3_Eq1PcUA"
      },
      "id": "bg_3_Eq1PcUA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Environment**"
      ],
      "metadata": {
        "id": "rR9j88UHRCJF"
      },
      "id": "rR9j88UHRCJF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Libraries**"
      ],
      "metadata": {
        "id": "jCIbohwJURxQ"
      },
      "id": "jCIbohwJURxQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f240f0d8-d9e0-4632-962f-1a5a7881cb5f",
      "metadata": {
        "id": "f240f0d8-d9e0-4632-962f-1a5a7881cb5f"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "\n",
        "# Data Manipulation\n",
        "import pandas as pd             # Pandas for handling and processing datasets.\n",
        "\n",
        "# Mathematical Operations\n",
        "import math                     # Math for mathematical functions and constants.\n",
        "import numpy as np              # NumPy for numerical computations and array handling.\n",
        "\n",
        "# PyTorch (Deep Learning Framework)\n",
        "import torch                    # Core PyTorch library.\n",
        "import torch.nn as nn           # Neural network module for building models.\n",
        "import torch.nn.functional as F # Functional API for additional neural network layers and operations.\n",
        "import torch.optim as optim     # Optimizers for model training.\n",
        "from torch.utils.data import Dataset, DataLoader # Dataset and DataLoader for handling data in batches.\n",
        "\n",
        "# Utilities\n",
        "from collections import Counter  # Counter for counting elements in data.\n",
        "import re                        # Regular expressions for text manipulation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Drive**"
      ],
      "metadata": {
        "id": "lyBf4xCuUXFV"
      },
      "id": "lyBf4xCuUXFV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ebcf8f0-fcf0-4cf7-a549-0c68aa8eab1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ebcf8f0-fcf0-4cf7-a549-0c68aa8eab1a",
        "outputId": "5290164e-00ac-423b-b781-ac527033c1db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google Drive in Google Colab.\n",
        "# Access to files and directories stored in Google Drive from a Colab notebook.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Device**"
      ],
      "metadata": {
        "id": "lfX8GEScUlYz"
      },
      "id": "lfX8GEScUlYz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a CUDA-enabled GPU is available; if so, set the device to GPU, otherwise use CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Print the selected device (either 'cuda' for GPU or 'cpu').\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w14PHwCT_uy",
        "outputId": "b99b5961-743e-4b52-cea0-3f7e0bdd34ea"
      },
      "id": "4w14PHwCT_uy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Loading**"
      ],
      "metadata": {
        "id": "4CZvf5xoQT0h"
      },
      "id": "4CZvf5xoQT0h"
    },
    {
      "cell_type": "markdown",
      "id": "17f54c65",
      "metadata": {
        "heading_collapsed": true,
        "id": "17f54c65"
      },
      "source": [
        "###**Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f02c0c2",
      "metadata": {
        "hidden": true,
        "collapsed": true,
        "id": "8f02c0c2"
      },
      "outputs": [],
      "source": [
        "# Define file path for the Spanish-English dataset.\n",
        "PATH = '/content/drive/MyDrive/Deep_Learning/eng-spa2024.csv'\n",
        "\n",
        "# Load dataset into a DataFrame using tab ('\\t') as the separator.\n",
        "df = pd.read_csv(PATH, encoding='latin1', header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**CVS File to TXT File**"
      ],
      "metadata": {
        "id": "O_IjeO2xU6_p"
      },
      "id": "O_IjeO2xU6_p"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the relevant columns for English and Spanish from the DataFrame.\n",
        "eng_spa_cols = df.iloc[:, [1, 3]]\n",
        "\n",
        "# Calculate the length of each entry in the first column (English text) and store it as a new column.\n",
        "eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()\n",
        "\n",
        "# Sort the DataFrame based on the 'length' column to order entries by the length of the English text.\n",
        "eng_spa_cols = eng_spa_cols.sort_values(by='length')\n",
        "\n",
        "# Remove the 'length' column after sorting, as it is no longer needed.\n",
        "eng_spa_cols = eng_spa_cols.drop(columns=['length'])\n",
        "\n",
        "# Define output file path and save the processed DataFrame to a new file without index or header.\n",
        "output_file_path = '/content/drive/MyDrive/Deep_Learning/eng-spa2024.txt'\n",
        "eng_spa_cols.to_csv(output_file_path, sep='\\t', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2exafyPtSv-U",
        "outputId": "11668950-8739-4c85-d097-8f50a8daec2a"
      },
      "id": "2exafyPtSv-U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-d05fb31b3075>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d468e9a",
      "metadata": {
        "id": "7d468e9a"
      },
      "source": [
        "##**Transformer - Attention Is All You Need**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a random seed for reproducibility in PyTorch operations.\n",
        "torch.manual_seed(23)\n",
        "\n",
        "# Define the maximum sequence length for input data, setting a limit for processing.\n",
        "MAX_SEQ_LEN = 128"
      ],
      "metadata": {
        "id": "CjCcnFOeUOr_"
      },
      "id": "CjCcnFOeUOr_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Positional Embedding**"
      ],
      "metadata": {
        "id": "qVxtzHObXS3C"
      },
      "id": "qVxtzHObXS3C"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a positional embedding layer for adding position information to token embeddings.\n",
        "class PositionalEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_seq_len=MAX_SEQ_LEN):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Create a matrix to store positional encodings for each token position.\n",
        "        self.pos_embed_matrix = torch.zeros(max_seq_len, d_model, device=device)\n",
        "\n",
        "        # Calculate sine and cosine position encodings.\n",
        "        token_pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        self.pos_embed_matrix[:, 0::2] = torch.sin(token_pos * div_term)\n",
        "        self.pos_embed_matrix[:, 1::2] = torch.cos(token_pos * div_term)\n",
        "\n",
        "        # Add a batch dimension and adjust shape for compatibility.\n",
        "        self.pos_embed_matrix = self.pos_embed_matrix.unsqueeze(0).transpose(0, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # print(self.pos_embed_matrix.shape)\n",
        "        # print(x.shape)\n",
        "\n",
        "        return x + self.pos_embed_matrix[:x.size(0), :]"
      ],
      "metadata": {
        "id": "suie3V1BXYXS"
      },
      "id": "suie3V1BXYXS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Multi Head Attention**"
      ],
      "metadata": {
        "id": "5rNPaVILXccZ"
      },
      "id": "5rNPaVILXccZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a multi-head attention layer for capturing various representation subspaces.\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model=512, num_heads=8):\n",
        "\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, 'Embedding size must be divisible by number of heads'\n",
        "\n",
        "        # Define dimensions for each attention head.\n",
        "        self.d_v = d_model // num_heads\n",
        "        self.d_k = self.d_v\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # Linear layers for projecting inputs into Q, K, V spaces.\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "\n",
        "        batch_size = Q.size(0)\n",
        "\n",
        "        # Q, K, V -> [batch_size, seq_len, num_heads*d_k] after transpose Q, K, V -> [batch_size, num_heads, seq_len, d_k]\n",
        "\n",
        "        # Project and reshape Q, K, V to enable multi-head attention.\n",
        "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Calculate attention output.\n",
        "        weighted_values, attention = self.scale_dot_product(Q, K, V, mask)\n",
        "\n",
        "        # Reshape the output back to original dimensions.\n",
        "        weighted_values = weighted_values.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
        "        weighted_values = self.W_o(weighted_values)\n",
        "\n",
        "        return weighted_values, attention\n",
        "\n",
        "    def scale_dot_product(self, Q, K, V, mask=None):\n",
        "\n",
        "        # Compute attention scores and apply mask if provided.\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attention = F.softmax(scores, dim=-1)\n",
        "\n",
        "        # Calculate weighted sum of values.\n",
        "        weighted_values = torch.matmul(attention, V)\n",
        "\n",
        "        return weighted_values, attention"
      ],
      "metadata": {
        "id": "Lfeh4s25Xh8u"
      },
      "id": "Lfeh4s25Xh8u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Position Feed Forward**"
      ],
      "metadata": {
        "id": "y29ugHiGYXup"
      },
      "id": "y29ugHiGYXup"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a feedforward neural network layer used within the Transformer.\n",
        "class PositionFeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, d_ff):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Two linear layers for the feedforward network.\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Apply ReLU activation between two linear transformations.\n",
        "        return self.linear2(F.relu(self.linear1(x)))"
      ],
      "metadata": {
        "id": "7IVY19dvYa7P"
      },
      "id": "7IVY19dvYa7P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Encoder Sub Layer**"
      ],
      "metadata": {
        "id": "HAcDr_ltYh-9"
      },
      "id": "HAcDr_ltYh-9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sublayer within the encoder, which includes attention and feedforward layers.\n",
        "class EncoderSubLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Self-attention and feedforward layers.\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = PositionFeedForward(d_model, d_ff)\n",
        "\n",
        "        # Normalization and dropout layers.\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "\n",
        "        # Apply self-attention, normalization, and residual connections.\n",
        "        attention_score, _ = self.self_attn(x, x, x, mask)\n",
        "        x = x + self.dropout1(attention_score)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Apply feedforward, normalization, and residual connections.\n",
        "        x = x + self.dropout2(self.ffn(x))\n",
        "\n",
        "        return self.norm2(x)"
      ],
      "metadata": {
        "id": "lRkPFe34YoFF"
      },
      "id": "lRkPFe34YoFF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Encoder**"
      ],
      "metadata": {
        "id": "ft4lz8__YtXC"
      },
      "id": "ft4lz8__YtXC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the encoder consisting of multiple sublayers for representation learning.\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Stack multiple encoder sublayers.\n",
        "        self.layers = nn.ModuleList([EncoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "\n",
        "        # Pass the input through each encoder layer.\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "jPZDiKmfYscH"
      },
      "id": "jPZDiKmfYscH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Decoder Sub Layer**"
      ],
      "metadata": {
        "id": "597R0iPFYzN3"
      },
      "id": "597R0iPFYzN3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sublayer within the decoder, incorporating self-attention, cross-attention, and feedforward layers.\n",
        "class DecoderSubLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Self-attention, cross-attention, and feedforward layers.\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionFeedForward(d_model, d_ff)\n",
        "\n",
        "        # Normalization and dropout layers.\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, target_mask=None, encoder_mask=None):\n",
        "\n",
        "        # Self-attention with target mask.\n",
        "        attention_score, _ = self.self_attn(x, x, x, target_mask)\n",
        "        x = x + self.dropout1(attention_score)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Cross-attention with encoder output and mask.\n",
        "        encoder_attn, _ = self.cross_attn(x, encoder_output, encoder_output, encoder_mask)\n",
        "        x = x + self.dropout2(encoder_attn)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        # Feedforward network with residual and normalization.\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = x + self.dropout3(ff_output)\n",
        "\n",
        "        return self.norm3(x)"
      ],
      "metadata": {
        "id": "yi4GwFclY2vV"
      },
      "id": "yi4GwFclY2vV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Decoder**"
      ],
      "metadata": {
        "id": "7YgsXYDrY7Lk"
      },
      "id": "7YgsXYDrY7Lk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the decoder consisting of multiple sublayers for sequence generation.\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Stack multiple decoder sublayers.\n",
        "        self.layers = nn.ModuleList([DecoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, encoder_output, target_mask, encoder_mask):\n",
        "\n",
        "        # Pass the input through each decoder layer.\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, target_mask, encoder_mask)\n",
        "\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "q2NDcnXqXAiA"
      },
      "id": "q2NDcnXqXAiA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Transformer**"
      ],
      "metadata": {
        "id": "jLcBqMrJbE4h"
      },
      "id": "jLcBqMrJbE4h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61070162",
      "metadata": {
        "code_folding": [],
        "id": "61070162"
      },
      "outputs": [],
      "source": [
        "# Define a Transformer model with encoder-decoder structure.\n",
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, input_vocab_size, target_vocab_size, max_len=MAX_SEQ_LEN, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Define embedding layers for input and target vocabulary.\n",
        "        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n",
        "\n",
        "        # Positional embedding to encode token positions.\n",
        "        self.pos_embedding = PositionalEmbedding(d_model, max_len)\n",
        "\n",
        "        # Define encoder and decoder modules.\n",
        "        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
        "        self.decoder = Decoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
        "\n",
        "        # Output layer to map decoder output to vocabulary space.\n",
        "        self.output_layer = nn.Linear(d_model, target_vocab_size)\n",
        "\n",
        "    def forward(self, source, target):\n",
        "\n",
        "        # Generate masks for encoder and decoder inputs.\n",
        "        source_mask, target_mask = self.mask(source, target)\n",
        "\n",
        "        # Apply embedding and positional encoding to source input.\n",
        "        source = self.encoder_embedding(source) * math.sqrt(self.encoder_embedding.embedding_dim)\n",
        "        source = self.pos_embedding(source)\n",
        "\n",
        "        # Pass through encoder.\n",
        "        encoder_output = self.encoder(source, source_mask)\n",
        "\n",
        "        # Apply embedding and positional encoding to target input.\n",
        "        target = self.decoder_embedding(target) * math.sqrt(self.decoder_embedding.embedding_dim)\n",
        "        target = self.pos_embedding(target)\n",
        "\n",
        "        # Pass through decoder.\n",
        "        output = self.decoder(target, encoder_output, target_mask, source_mask)\n",
        "\n",
        "        # Map decoder output to target vocabulary size.\n",
        "        return self.output_layer(output)\n",
        "\n",
        "    def mask(self, source, target):\n",
        "\n",
        "        # Create source mask (1 for non-padding tokens, 0 for padding).\n",
        "        source_mask = (source != 0).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # Create target mask (1 for non-padding tokens, 0 for padding).\n",
        "        target_mask = (target != 0).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # Generate triangular mask to prevent attending to future tokens.\n",
        "        size = target.size(1)\n",
        "        no_mask = torch.tril(torch.ones((1, size, size), device=device)).bool()\n",
        "        target_mask = target_mask & no_mask\n",
        "\n",
        "        return source_mask, target_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da6b2d4",
      "metadata": {
        "heading_collapsed": true,
        "id": "6da6b2d4"
      },
      "source": [
        "##**Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40581d6",
      "metadata": {
        "hidden": true,
        "id": "d40581d6"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "seq_len_source = 10           # Length of each source sequence.\n",
        "seq_len_target = 10           # Length of each target sequence.\n",
        "batch_size = 2                # Number of samples in each batch.\n",
        "input_vocab_size = 50         # Vocabulary size for source language.\n",
        "target_vocab_size = 50        # Vocabulary size for target language.\n",
        "\n",
        "# Generate random source and target sequences as input data.\n",
        "source = torch.randint(1, input_vocab_size, (batch_size, seq_len_source))  # Random source sequence tensor.\n",
        "target = torch.randint(1, target_vocab_size, (batch_size, seq_len_target)) # Random target sequence tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc7cf689",
      "metadata": {
        "hidden": true,
        "id": "fc7cf689"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters for the Transformer Model\n",
        "d_model = 512        # Dimensionality of the model (embedding size).\n",
        "num_heads = 8        # Number of attention heads in multi-head attention.\n",
        "d_ff = 2048          # Dimension of the feedforward layer.\n",
        "num_layers = 6       # Number of layers in both encoder and decoder.\n",
        "\n",
        "# Instantiate the Transformer model with the specified parameters.\n",
        "model = Transformer(d_model, num_heads, d_ff, num_layers, input_vocab_size, target_vocab_size, max_len=MAX_SEQ_LEN, dropout=0.1)\n",
        "\n",
        "# Move the model and input tensors to the specified device (GPU or CPU).\n",
        "model = model.to(device)\n",
        "source = source.to(device)\n",
        "target = target.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4618560e",
      "metadata": {
        "hidden": true,
        "id": "4618560e"
      },
      "outputs": [],
      "source": [
        "# Perform a forward pass through the model with source and target sequences.\n",
        "output = model(source, target)  # Get the model's output for the given input sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab0bc69d",
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab0bc69d",
        "outputId": "7ae7f13b-d520-4e34-b78f-c8f32d1eb405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ouput.shape torch.Size([2, 10, 50])\n"
          ]
        }
      ],
      "source": [
        "# Expected output shape -> [batch, seq_len_target, target_vocab_size] i.e. [2, 10, 50]\n",
        "\n",
        "# Print the shape of the output tensor to verify dimensions.\n",
        "print(f'ouput.shape {output.shape}')  # Output shape of the model's prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4b2910",
      "metadata": {
        "id": "0f4b2910"
      },
      "source": [
        "## **Translator Eng-Spa**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "869a7244",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "869a7244",
        "outputId": "20293f31-af44-4245-e91c-857102d9fb08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No!', 'Hi.', 'Ah!', 'OK.', 'Ok!', 'So?', 'Go.', 'Go.', 'Go.', 'So?']\n",
            "['Â¡No!', 'Â¡Hola!', 'Â¡Anda!', 'Â¡Ã\\x93rale!', 'Â¡OK!', 'Â¿Y quÃ©?', 'Ve.', 'Vete.', 'Vaya.', 'Â¿Entonces?']\n"
          ]
        }
      ],
      "source": [
        "# Define the path to the text file containing English-Spanish sentence pairs.\n",
        "PATH = '/content/drive/MyDrive/Deep_Learning/eng-spa2024.txt'\n",
        "\n",
        "# Open the file and read all lines with UTF-8 encoding.\n",
        "with open(PATH, 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Split each line into English-Spanish pairs, ignoring lines without a tab separator.\n",
        "eng_spa_pairs = [line.strip().split('\\t') for line in lines if '\\t' in line]\n",
        "\n",
        "# Display the first 10 English-Spanish pairs.\n",
        "eng_spa_pairs[:10]\n",
        "\n",
        "# Extract the English sentences from the pairs.\n",
        "eng_sentences = [pair[0] for pair in eng_spa_pairs]\n",
        "\n",
        "# Extract the Spanish sentences from the pairs.\n",
        "spa_sentences = [pair[1] for pair in eng_spa_pairs]\n",
        "\n",
        "# Print the first 10 English and Spanish sentences.\n",
        "print(eng_sentences[:10])\n",
        "print(spa_sentences[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Preprocess Sentences**"
      ],
      "metadata": {
        "id": "TiT-ZiI0wRQF"
      },
      "id": "TiT-ZiI0wRQF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60d11478",
      "metadata": {
        "id": "60d11478"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "\n",
        "    # Convert sentence to lowercase and remove leading/trailing whitespace.\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    # Replace multiple spaces with a single space.\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "    # Normalize accented characters to their non-accented equivalents.\n",
        "    sentence = re.sub(r\"[á]+\", \"a\", sentence)\n",
        "    sentence = re.sub(r\"[é]+\", \"e\", sentence)\n",
        "    sentence = re.sub(r\"[í]+\", \"i\", sentence)\n",
        "    sentence = re.sub(r\"[ó]+\", \"o\", sentence)\n",
        "    sentence = re.sub(r\"[ú]+\", \"u\", sentence)\n",
        "\n",
        "    # Remove non-alphabetic characters.\n",
        "    sentence = re.sub(r\"[^a-z]+\", \" \", sentence)\n",
        "\n",
        "    # Remove leading/trailing spaces after cleaning.\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    # Add start and end tokens to sentence.\n",
        "    sentence = '<sos> ' + sentence + ' <eos>'\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "478f673b",
      "metadata": {
        "id": "478f673b"
      },
      "outputs": [],
      "source": [
        "s1 = '¿Hola @ cómo estás? 123'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96ac79c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96ac79c5",
        "outputId": "f0f9b65a-de05-44c9-d5c5-fa9a482370b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Hola @ cómo estás? 123\n",
            "<sos> hola como estas <eos>\n"
          ]
        }
      ],
      "source": [
        "print(s1)\n",
        "print(preprocess_sentence(s1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9fc9c4d",
      "metadata": {
        "id": "d9fc9c4d"
      },
      "outputs": [],
      "source": [
        "eng_sentences = [preprocess_sentence(sentence) for sentence in eng_sentences]\n",
        "spa_sentences = [preprocess_sentence(sentence) for sentence in spa_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7a3b18d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7a3b18d",
        "outputId": "e43749aa-fa73-44dc-bb25-900015d18dcb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> no <eos>',\n",
              " '<sos> hola <eos>',\n",
              " '<sos> anda <eos>',\n",
              " '<sos> rale <eos>',\n",
              " '<sos> ok <eos>',\n",
              " '<sos> y qu <eos>',\n",
              " '<sos> ve <eos>',\n",
              " '<sos> vete <eos>',\n",
              " '<sos> vaya <eos>',\n",
              " '<sos> entonces <eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "spa_sentences[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Build Vocabulary**"
      ],
      "metadata": {
        "id": "qaQCYG47wtvV"
      },
      "id": "qaQCYG47wtvV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97931cd3",
      "metadata": {
        "id": "97931cd3"
      },
      "outputs": [],
      "source": [
        "def build_vocab(sentences):\n",
        "\n",
        "    # Flatten the list of sentences into individual words.\n",
        "    words = [word for sentence in sentences for word in sentence.split()]\n",
        "\n",
        "    # Count the occurrences of each word.\n",
        "    word_count = Counter(words)\n",
        "\n",
        "    # Sort words by frequency in descending order.\n",
        "    sorted_word_counts = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
        "\n",
        "    # Create a mapping of words to indices starting from index 2.\n",
        "    word2idx = {word: idx for idx, (word, _) in enumerate(sorted_word_counts, 2)}\n",
        "\n",
        "    # Add special tokens for padding and unknown words.\n",
        "    word2idx['<pad>'] = 0\n",
        "    word2idx['<unk>'] = 1\n",
        "\n",
        "    # Reverse the mapping: indices to words.\n",
        "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "\n",
        "    return word2idx, idx2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fa8738e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fa8738e",
        "outputId": "387d0ea1-a44a-4e4e-aa31-ad6a7c05f78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27672 43296\n"
          ]
        }
      ],
      "source": [
        "# Build vocabulary for English and Spanish sentences.\n",
        "eng_word2idx, eng_idx2word = build_vocab(eng_sentences)\n",
        "spa_word2idx, spa_idx2word = build_vocab(spa_sentences)\n",
        "\n",
        "# Get the vocabulary sizes for both languages.\n",
        "eng_vocab_size = len(eng_word2idx)\n",
        "spa_vocab_size = len(spa_word2idx)\n",
        "\n",
        "# Print the vocabulary sizes.\n",
        "print(eng_vocab_size, spa_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**English-Spanish Dataset**"
      ],
      "metadata": {
        "id": "Z9uQgCxIxU1O"
      },
      "id": "Z9uQgCxIxU1O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e564017c",
      "metadata": {
        "id": "e564017c"
      },
      "outputs": [],
      "source": [
        "# Define a custom Dataset for English-Spanish sentence pairs.\n",
        "class EngSpaDataset(Dataset):\n",
        "\n",
        "    # Initialize dataset with English and Spanish sentences and vocab mappings.\n",
        "    def __init__(self, eng_sentences, spa_sentences, eng_word2idx, spa_word2idx):\n",
        "\n",
        "        self.eng_sentences = eng_sentences  # List of English sentences.\n",
        "        self.spa_sentences = spa_sentences  # List of Spanish sentences.\n",
        "\n",
        "        self.eng_word2idx = eng_word2idx  # English word-to-index dictionary.\n",
        "        self.spa_word2idx = spa_word2idx  # Spanish word-to-index dictionary.\n",
        "\n",
        "    # Return the number of sentences in the dataset.\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.eng_sentences)\n",
        "\n",
        "    # Return the tokenized index version of an English-Spanish sentence pair.\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        eng_sentence = self.eng_sentences[idx]  # Get the English sentence at the given index.\n",
        "        spa_sentence = self.spa_sentences[idx]  # Get the Spanish sentence at the given index.\n",
        "\n",
        "        # Convert English and Spanish sentences to indices using respective vocabularies.\n",
        "        eng_idxs = [self.eng_word2idx.get(word, self.eng_word2idx['<unk>']) for word in eng_sentence.split()]\n",
        "        spa_idxs = [self.spa_word2idx.get(word, self.spa_word2idx['<unk>']) for word in spa_sentence.split()]\n",
        "\n",
        "        # Return the tokenized English and Spanish sentences as tensors.\n",
        "        return torch.tensor(eng_idxs), torch.tensor(spa_idxs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b579577b",
      "metadata": {
        "id": "b579577b"
      },
      "outputs": [],
      "source": [
        "# Custom collate function to process a batch of sentences for the DataLoader.\n",
        "def collate_fn(batch):\n",
        "\n",
        "    # Unzip the batch into English and Spanish sentence pairs.\n",
        "    eng_batch, spa_batch = zip(*batch)\n",
        "\n",
        "    # Truncate or pad English sentences to a maximum sequence length (MAX_SEQ_LEN).\n",
        "    eng_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in eng_batch]\n",
        "\n",
        "    # Truncate or pad Spanish sentences to a maximum sequence length (MAX_SEQ_LEN).\n",
        "    spa_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in spa_batch]\n",
        "\n",
        "    # Pad the English sentences to ensure all sequences in the batch are of equal length.\n",
        "    eng_batch = torch.nn.utils.rnn.pad_sequence(eng_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Pad the Spanish sentences to ensure all sequences in the batch are of equal length.\n",
        "    spa_batch = torch.nn.utils.rnn.pad_sequence(spa_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Return the padded English and Spanish sentence batches.\n",
        "    return eng_batch, spa_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Training**"
      ],
      "metadata": {
        "id": "XrZLMRg8xhld"
      },
      "id": "XrZLMRg8xhld"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d514b7c",
      "metadata": {
        "id": "8d514b7c"
      },
      "outputs": [],
      "source": [
        "# Training loop for the Transformer model\n",
        "def train(model, dataloader, loss_function, optimiser, epochs):\n",
        "\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0  # Initialize total loss for the epoch\n",
        "\n",
        "        # Loop over batches in the dataloader\n",
        "        for i, (eng_batch, spa_batch) in enumerate(dataloader):\n",
        "            # Move batches to the device (GPU or CPU)\n",
        "            eng_batch = eng_batch.to(device)\n",
        "            spa_batch = spa_batch.to(device)\n",
        "\n",
        "            # Preprocess target (Spanish) sentences for the decoder\n",
        "            target_input = spa_batch[:, :-1]  # Remove last token for input to decoder\n",
        "            target_output = spa_batch[:, 1:].contiguous().view(-1)  # Flatten target output\n",
        "\n",
        "            # Zero the gradients before backpropagation\n",
        "            optimiser.zero_grad()\n",
        "\n",
        "            # Run the model and get output\n",
        "            output = model(eng_batch, target_input)\n",
        "            output = output.view(-1, output.size(-1))  # Flatten the output for loss calculation\n",
        "\n",
        "            # Compute loss between model output and target output\n",
        "            loss = loss_function(output, target_output)\n",
        "\n",
        "            # Backpropagation and parameter update\n",
        "            loss.backward()\n",
        "            optimiser.step()\n",
        "\n",
        "            # Accumulate loss for the current batch\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Calculate average loss for the epoch\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "        # Print progress at the end of the epoch\n",
        "        print(f'Epoch: {epoch}/{epochs}, Loss: {avg_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2379ea72",
      "metadata": {
        "id": "2379ea72"
      },
      "outputs": [],
      "source": [
        "# Define batch size for training.\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Initialize the dataset for English-Spanish sentence pairs.\n",
        "dataset = EngSpaDataset(eng_sentences, spa_sentences, eng_word2idx, spa_word2idx)\n",
        "\n",
        "# Create a DataLoader for batching, shuffling, and padding sequences.\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e08eef6a",
      "metadata": {
        "id": "e08eef6a"
      },
      "outputs": [],
      "source": [
        "# Initialize the Transformer model with specified hyperparameters.\n",
        "model = Transformer(\n",
        "    d_model=512,                      # Dimension of the model (embedding size).\n",
        "    num_heads=8,                      # Number of attention heads in multi-head attention.\n",
        "    d_ff=2048,                        # Dimensionality of the feed-forward network.\n",
        "    num_layers=6,                     # Number of encoder and decoder layers.\n",
        "    input_vocab_size=eng_vocab_size,  # Vocabulary size for input (English).\n",
        "    target_vocab_size=spa_vocab_size, # Vocabulary size for output (Spanish).\n",
        "    max_len=MAX_SEQ_LEN,              # Maximum sequence length.\n",
        "    dropout=0.1                       # Dropout rate for regularization.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1181a12",
      "metadata": {
        "id": "a1181a12"
      },
      "outputs": [],
      "source": [
        "# Move the model to the specified device (GPU/CPU).\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function as CrossEntropyLoss, ignoring padding index (0).\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "# Set up the Adam optimizer with a learning rate of 0.0001 for model parameters.\n",
        "optimiser = optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e265e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14e265e9",
        "outputId": "b44a8f3e-27f1-4277-a31e-6296982500d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/10, Loss: 1.8932\n",
            "Epoch: 1/10, Loss: 1.4995\n",
            "Epoch: 2/10, Loss: 1.2226\n",
            "Epoch: 3/10, Loss: 1.0036\n",
            "Epoch: 4/10, Loss: 0.8277\n",
            "Epoch: 5/10, Loss: 0.6853\n",
            "Epoch: 6/10, Loss: 0.5759\n",
            "Epoch: 7/10, Loss: 0.4951\n",
            "Epoch: 8/10, Loss: 0.4373\n",
            "Epoch: 9/10, Loss: 0.3943\n"
          ]
        }
      ],
      "source": [
        "# Train the model using the provided data loader, loss function, optimizer, and number of epochs (10).\n",
        "train(model, dataloader, loss_function, optimiser, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Translate Sentences**"
      ],
      "metadata": {
        "id": "gZHUas2DzrmX"
      },
      "id": "gZHUas2DzrmX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert a sentence into a list of word indices using the provided word-to-index mapping.\n",
        "def sentence_to_indices(sentence, word2idx):\n",
        "    return [word2idx.get(word, word2idx['<unk>']) for word in sentence.split()]\n",
        "\n",
        "# Convert a list of indices back into a sentence using the provided index-to-word mapping.\n",
        "def indices_to_sentence(indices, idx2word):\n",
        "    return ' '.join([idx2word[idx] for idx in indices if idx in idx2word and idx2word[idx] != '<pad>'])"
      ],
      "metadata": {
        "id": "Wshl54Wr0aBH"
      },
      "id": "Wshl54Wr0aBH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50740746",
      "metadata": {
        "code_folding": [],
        "id": "50740746"
      },
      "outputs": [],
      "source": [
        "# Translate a sentence using the trained model by encoding the input and generating a target sequence.\n",
        "def translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
        "    model.eval()  # Set the model to evaluation mode.\n",
        "    sentence = preprocess_sentence(sentence)  # Preprocess the input sentence.\n",
        "    input_indices = sentence_to_indices(sentence, eng_word2idx)  # Convert the sentence to indices.\n",
        "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)  # Convert indices to tensor.\n",
        "\n",
        "    # Initialize the target sequence with the <sos> token.\n",
        "    tgt_indices = [spa_word2idx['<sos>']]\n",
        "    tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation during inference.\n",
        "        for _ in range(max_len):  # Generate tokens until max length or <eos> is reached.\n",
        "            output = model(input_tensor, tgt_tensor)  # Get model's output.\n",
        "            output = output.squeeze(0)\n",
        "            next_token = output.argmax(dim=-1)[-1].item()  # Get the most probable token.\n",
        "            tgt_indices.append(next_token)  # Append the token to the target sequence.\n",
        "            tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)  # Update target tensor.\n",
        "            if next_token == spa_word2idx['<eos>']:  # Stop if <eos> token is generated.\n",
        "                break\n",
        "\n",
        "    return indices_to_sentence(tgt_indices, spa_idx2word)  # Convert generated indices back to a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Evaluate Translations**"
      ],
      "metadata": {
        "id": "x14sYJLl0lCR"
      },
      "id": "x14sYJLl0lCR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the translations of a list of sentences using the trained model.\n",
        "def evaluate_translations(model, sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
        "\n",
        "    # Iterate through each sentence in the provided list.\n",
        "    for sentence in sentences:\n",
        "        # Translate the sentence using the trained model.\n",
        "        translation = translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len, device)\n",
        "\n",
        "        # Print the original sentence and its translation.\n",
        "        print(f'Input Sentence: {sentence}')\n",
        "        print(f'Translation: {translation}')\n",
        "        print()"
      ],
      "metadata": {
        "id": "-NtgD8O-0s5B"
      },
      "id": "-NtgD8O-0s5B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c0db72",
      "metadata": {
        "code_folding": [
          15
        ],
        "id": "c2c0db72"
      },
      "outputs": [],
      "source": [
        "# Sentences to test the translator.\n",
        "test_sentences = [\n",
        "    \"The weather is nice today.\",\n",
        "    \"Can you help me with this problem?\",\n",
        "    \"Python is a powerful programming language.\",\n",
        "    \"I love learning new things.\",\n",
        "    \"This coffee tastes amazing!\",\n",
        "    \"Did you watch the game last night?\",\n",
        "    \"The sun is shining brightly.\",\n",
        "    \"Learning to code can be fun.\",\n",
        "    \"She enjoys reading books on the weekend.\",\n",
        "    \"Tomorrow is going to be a busy day.\",\n",
        "    \"He plays the guitar really well.\",\n",
        "    \"I need to finish my project by Friday.\",\n",
        "    \"Where did you buy that shirt?\",\n",
        "    \"This is a wonderful opportunity.\",\n",
        "    \"It's raining heavily outside.\",\n",
        "    \"Can you recommend a good restaurant?\",\n",
        "    \"The train arrives in ten minutes.\",\n",
        "    \"What time does the meeting start?\",\n",
        "    \"I am planning a trip to the mountains.\",\n",
        "    \"We should try that new recipe tonight.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available and set the device accordingly.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the selected device (GPU/CPU).\n",
        "model = model.to(device)\n",
        "\n",
        "# Evaluate the translations for the test sentences.\n",
        "evaluate_translations(model, test_sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukDdhFIn1ciV",
        "outputId": "666d32bc-02b2-456a-d695-555b7c5fa88f"
      },
      "id": "ukDdhFIn1ciV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence: The weather is nice today.\n",
            "Translation: <sos> hoy hace bueno <eos>\n",
            "\n",
            "Input Sentence: Can you help me with this problem?\n",
            "Translation: <sos> puedes ayudarme con este problema <eos>\n",
            "\n",
            "Input Sentence: Python is a powerful programming language.\n",
            "Translation: <sos> la programaci n es un lenguaje poderoso <eos>\n",
            "\n",
            "Input Sentence: I love learning new things.\n",
            "Translation: <sos> adoro aprender nuevas cosas <eos>\n",
            "\n",
            "Input Sentence: This coffee tastes amazing!\n",
            "Translation: <sos> este caf sabe estupendo <eos>\n",
            "\n",
            "Input Sentence: Did you watch the game last night?\n",
            "Translation: <sos> viste el partido anoche <eos>\n",
            "\n",
            "Input Sentence: The sun is shining brightly.\n",
            "Translation: <sos> el sol brilla con fuerza <eos>\n",
            "\n",
            "Input Sentence: Learning to code can be fun.\n",
            "Translation: <sos> aprender a ser divertido <eos>\n",
            "\n",
            "Input Sentence: She enjoys reading books on the weekend.\n",
            "Translation: <sos> ella disfruta leer libros el fin de semana <eos>\n",
            "\n",
            "Input Sentence: Tomorrow is going to be a busy day.\n",
            "Translation: <sos> ma ana va a estar ocupado <eos>\n",
            "\n",
            "Input Sentence: He plays the guitar really well.\n",
            "Translation: <sos> l toca muy bien la guitarra <eos>\n",
            "\n",
            "Input Sentence: I need to finish my project by Friday.\n",
            "Translation: <sos> necesito terminar mi proyecto para el viernes <eos>\n",
            "\n",
            "Input Sentence: Where did you buy that shirt?\n",
            "Translation: <sos> d nde compraste esa camisa <eos>\n",
            "\n",
            "Input Sentence: This is a wonderful opportunity.\n",
            "Translation: <sos> esta es una oportunidad maravillosa <eos>\n",
            "\n",
            "Input Sentence: It's raining heavily outside.\n",
            "Translation: <sos> afuera llueve mucho <eos>\n",
            "\n",
            "Input Sentence: Can you recommend a good restaurant?\n",
            "Translation: <sos> me puede recomendar un buen restaurante <eos>\n",
            "\n",
            "Input Sentence: The train arrives in ten minutes.\n",
            "Translation: <sos> el tren llega en diez minutos <eos>\n",
            "\n",
            "Input Sentence: What time does the meeting start?\n",
            "Translation: <sos> a qu hora empieza la reuni n <eos>\n",
            "\n",
            "Input Sentence: I am planning a trip to the mountains.\n",
            "Translation: <sos> estoy planeando un viaje a las monta as <eos>\n",
            "\n",
            "Input Sentence: We should try that new recipe tonight.\n",
            "Translation: <sos> deber amos intentar esa nueva receta esta noche <eos>\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}